import json
from sklearn.decomposition import PCA
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
import streamlit.components.v1 as components
from time import sleep
from distancia_minima import run_distancia_minima
from kdd import run_kdtree
from knn import run_knn
st.header("Cesar Abraham Delgado Cardona")
# T√≠tulo del proyecto
st.title("Comparador de Clasificadores")

# Descripci√≥n del proyecto
st.markdown(
    """
    Esta aplicaci√≥n permite experimentar con distintos clasificadores de Machine Learning
    utilizando archivos CSV personalizados. Se pueden seleccionar m√∫ltiples clasificadores,
    ajustar sus par√°metros y comparar m√©tricas de desempe√±o como precisi√≥n, exactitud,
    sensibilidad, especificidad y tiempo de ejecuci√≥n.
    
    ### Instrucciones: 
    1. Cargue un archivo CSV con datos.
    2. Elija los clasificadores a probar y ajuste sus par√°metros.
    3. Compare los resultados obtenidos.
    """
)
# Funci√≥n para reiniciar la aplicaci√≥n
def reset_app():
    st.session_state.clear()
    st.markdown("<meta http-equiv='refresh' content='0'>", unsafe_allow_html=True)
st.divider()

# Carga de archivo CSV
st.sidebar.header("Carga de Datos")
uploaded_file = st.sidebar.file_uploader("Seleccione un archivo CSV", type=["csv"])
# Opci√≥n en el sidebar para mostrar estad√≠sticas
display_stats = st.sidebar.checkbox("Ver detalles y estad√≠stica", value=False)

if uploaded_file is not None:
    # Leer el archivo solo si no ha sido guardado en session_state
    if "df" not in st.session_state:
        df = pd.read_csv(uploaded_file)
        st.session_state["df_original"] = df.copy()  # Guardar una copia original sin modificar
        st.session_state["df"] = df  # Guardar el DataFrame modificado
    else:
        df = st.session_state["df"]  # Usar el DataFrame almacenado
    
    # Detecci√≥n autom√°tica de la variable objetivo (√∫ltima columna por defecto, pero validada)
    target_column = df.columns[-1]  # √öltima columna por defecto
    if df[target_column].nunique() > df.shape[0] * 0.5:  # Si tiene demasiados valores √∫nicos, no es categ√≥rica
        st.error("‚ö†Ô∏è No se detect√≥ una variable objetivo categ√≥rica en la √∫ltima columna. Seleccione manualmente.")
    else:
        if display_stats:
            
            st.write("### üìÑ Vista previa de los datos:")
            st.write(df.head())

            # Identificar TODAS las columnas categ√≥ricas (incluyendo la variable objetivo si es categ√≥rica)
            categorical_columns = df.select_dtypes(include=['object']).columns.tolist()

            # Convertir columnas categ√≥ricas a num√©ricas usando LabelEncoder
            label_encoders = {}
            for col in categorical_columns:
                le = LabelEncoder()
                df[col] = le.fit_transform(df[col])
                label_encoders[col] = le

            # Verificar si a√∫n quedan columnas no num√©ricas antes de continuar
            non_numeric_cols = df.select_dtypes(include=['object']).columns.tolist()
            if non_numeric_cols:
                st.error(f"‚ö†Ô∏è A√∫n existen columnas no num√©ricas en el dataset: {non_numeric_cols}. Aseg√∫rese de que todas fueron convertidas correctamente.")
                st.stop()

            # **Verificar si la variable objetivo tiene valores nulos despu√©s de la conversi√≥n**
            if df[target_column].isnull().any():
                st.error(f"‚ö†Ô∏è La variable objetivo `{target_column}` contiene {df[target_column].isnull().sum()} valores nulos. Filtrando datos...")
                df = df.dropna(subset=[target_column])  # Eliminar filas con etiquetas nulas

            # **Normalizaci√≥n de datos (excepto la variable objetivo)**
            scaler = MinMaxScaler()
            features = df.drop(columns=[target_column])
            df[features.columns] = scaler.fit_transform(features)

            # **Detecci√≥n del n√∫mero de clases**
            num_classes = df[target_column].nunique()
            num_features = df.shape[1] - 1  # N√∫mero de caracter√≠sticas sin contar la variable objetivo

            # **Guardar en `st.session_state`**
            st.session_state["num_classes"] = num_classes
            st.session_state["num_features"] = num_features
            st.session_state["df"] = df  # Guardar el DataFrame modificado para usar en experimentos

            # **Forzar conversi√≥n a valores num√©ricos antes de entrenar**
            st.session_state["df"] = df.apply(pd.to_numeric, errors='coerce')

            # **Verificar si despu√©s de la conversi√≥n hay valores nulos y eliminarlos**
            if st.session_state["df"].isnull().any().any():
                st.warning("‚ö†Ô∏è Se detectaron valores nulos despu√©s de la conversi√≥n. Eliminando filas con valores faltantes...")
                st.session_state["df"].dropna(inplace=True)

            # **M√°ximo permitido para LDA (asegurar que no exceda las caracter√≠sticas o clases)**
            max_components_lda = max(1, min(num_classes - 1, num_features))

            st.write("### üîç Datos normalizados:")
            st.write(st.session_state["df"].head())
            
            # Visualizaci√≥n interactiva de la distribuci√≥n de datos
            st.write("### üìä Distribuci√≥n de los datos normalizados")
            df_long = df.melt(id_vars=[target_column], var_name="Caracter√≠stica", value_name="Valor")
            fig = px.histogram(df_long, x="Valor", color="Caracter√≠stica", nbins=30, 
                                animation_frame="Caracter√≠stica", title="Distribuci√≥n de los Datos")
            st.plotly_chart(fig)
            
            # C√°lculo de estad√≠sticas descriptivas
            st.write("### üìà Estad√≠sticas Descriptivas")
            stats_df = pd.DataFrame({
                "Media": df.drop(columns=[target_column]).mean(),
                "Mediana": df.drop(columns=[target_column]).median(),
                "Moda": df.drop(columns=[target_column]).mode().iloc[0],
                "Desviaci√≥n Est√°ndar": df.drop(columns=[target_column]).std(),
                "M√≠nimo": df.drop(columns=[target_column]).min(),
                "M√°ximo": df.drop(columns=[target_column]).max()
            })
            stats_df.reset_index(inplace=True)
            stats_df.rename(columns={"index": "Caracter√≠stica"}, inplace=True)
            
            # Gr√°fico interactivo de estad√≠sticas descriptivas
            fig_stats = px.bar(stats_df.melt(id_vars=["Caracter√≠stica"], var_name="M√©trica", value_name="Valor"),
                                x="Caracter√≠stica", y="Valor", color="M√©trica", 
                                animation_frame="M√©trica", barmode="group", 
                                title="üìä Estad√≠sticas Descriptivas de los Datos")
            st.plotly_chart(fig_stats)
else:
    st.error("‚ö†Ô∏è Por favor, cargue un archivo CSV para continuar.")

#Bot√≥n para reiniciar toda la aplicaci√≥n
if st.sidebar.button("üîÑ Reiniciar Todo"):
    reset_app()

# Inicializaci√≥n de variables en session_state
if "num_classes" not in st.session_state:
    st.session_state.num_classes = 3  # Valor predeterminado
if "num_features" not in st.session_state:
    st.session_state.num_features = 5  # Valor predeterminado
if "classifier_list" not in st.session_state:
    st.session_state.classifier_list = ["KNN", "Distancia M√≠nima", "KD-Tree"]
if "classifier_configs" not in st.session_state or not isinstance(st.session_state.classifier_configs, list):
    st.session_state.classifier_configs = []  # Asegurar que sea una lista
if "experiment_ready" not in st.session_state:
    st.session_state.experiment_ready = False
if "results" not in st.session_state:
    st.session_state.results = []

# Funci√≥n para reiniciar el proceso
def reset_experiment():
    st.session_state.classifier_configs = []
    st.session_state.experiment_ready = False
    st.session_state.results = []
    st.rerun()

# Selecci√≥n de clasificadores
st.sidebar.header("Selecci√≥n de Clasificadores")
selected_classifiers = st.sidebar.selectbox("Seleccione un clasificador para configurar", st.session_state.classifier_list)


# Configuraci√≥n de clasificadores en secuencia
if selected_classifiers:
    # N√∫mero de clases y caracter√≠sticas
    num_classes = st.session_state["num_classes"]
    num_features = st.session_state["num_features"]

    # M√°ximo permitido para LDA
    max_components_lda = max(1, min(num_classes - 1, num_features))
    
        
    params = {}
    if selected_classifiers == "KNN":
        params["Optimizar valor de K"] = st.checkbox("Optimizar valor de K", value=True)
        if not params["Optimizar valor de K"]:
            params["K"] = st.number_input("N√∫mero de vecinos (K)", min_value=1, value=3)
        params["M√©trica"] = st.selectbox("M√©trica de distancia", ["Euclidiana", "Manhattan", "Chebyshev"])
        params["Ponderaci√≥n"] = st.selectbox("Ponderaci√≥n de vecinos", ["Uniforme", "Distancia"])
        params["Tecnica de validaci√≥n"] = st.selectbox("T√©cnica de validaci√≥n", ["Holdout", "K-Fold"])
        if params["Tecnica de validaci√≥n"] == "K-Fold":
            params["Folds"] = st.slider("N√∫mero de Folds", min_value=2, max_value=20, value=10)
        elif params["Tecnica de validaci√≥n"] == "Holdout":
            params["Proporci√≥n"] = st.number_input("Proporci√≥n de datos de entrenamiento", min_value=0.1, max_value=0.9, value=0.8)

        # Reducci√≥n de dimensionalidad
        params["Reducci√≥n de dimensionalidad"] = st.selectbox("Reducci√≥n de dimensionalidad", ["Ninguna", "PCA", "LDA"])

        if params["Reducci√≥n de dimensionalidad"] == "PCA":
            # Determinar el n√∫mero m√°ximo de componentes permitidos
            max_components = min(df.iloc[:, :-1].shape)

            # Bot√≥n para ejecutar PCA autom√°ticamente
            if st.button("Ejecutar PCA autom√°ticamente"):
                pca = PCA(n_components=max_components)  # Ajustar el n√∫mero m√°ximo permitido
                pca.fit(df.iloc[:, :-1])  # Aplicar PCA a las caracter√≠sticas
                
                explained_variance = np.cumsum(pca.explained_variance_ratio_)
                optimal_components = np.argmax(explained_variance >= params.get("Varianza", 0.95)) + 1
                optimal_components = min(optimal_components, max_components)  # Asegurar que no exceda el l√≠mite

                params["Componentes"] = optimal_components

                # Graficar la varianza explicada
                fig, ax = plt.subplots()
                sns.lineplot(x=range(1, max_components + 1), y=explained_variance, marker='o', ax=ax)
                ax.axhline(y=params.get("Varianza", 0.95), color='r', linestyle='--', label=f'{params.get("Varianza", 0.95) * 100}% Varianza Explicada')
                ax.axvline(x=optimal_components, color='g', linestyle='--', label=f'{optimal_components} Componentes')
                ax.set_xlabel("N√∫mero de Componentes")
                ax.set_ylabel("Varianza Explicada Acumulada")
                ax.set_title("An√°lisis de Componentes Principales (PCA)")
                ax.legend()
                st.pyplot(fig)

            # Configuraci√≥n manual de par√°metros con control del l√≠mite
            params["Componentes"] = st.slider(
                "N√∫mero de componentes para PCA", 
                min_value=1, 
                max_value=max_components, 
                value=params.get("Componentes", min(2, max_components))
            )
            params["Varianza"] = st.number_input("Varianza m√≠nima a explicar", min_value=0.0, max_value=1.0, value=params.get("Varianza", 0.95))


        elif params["Reducci√≥n de dimensionalidad"] == "LDA":
            params["N√∫mero de clases"] = num_classes  # Determinar autom√°ticamente
            params["Componentes"] = max_components_lda  # Ajuste autom√°tico
            st.write(f"LDA se aplicar√° con {max_components_lda} componentes (clases - 1)")
            
    # Clasificador de Distancia M√≠nima       
    elif selected_classifiers == "Distancia M√≠nima":
        params["M√©trica"] = st.selectbox("M√©trica de distancia", ["Euclidiana", "Manhattan", "Chebyshev"])
        params["Tecnica de validaci√≥n"] = st.selectbox("T√©cnica de validaci√≥n", ["Holdout", "K-Fold"])
        if params["Tecnica de validaci√≥n"] == "K-Fold":
            params["Folds"] = st.slider("N√∫mero de Folds", min_value=2, value=10)
        elif params["Tecnica de validaci√≥n"] == "Holdout":
            params["Proporci√≥n"] = st.number_input("Proporci√≥n de datos de entrenamiento", min_value=0.1, max_value=0.9, value=0.8)
        params["Reducci√≥n de dimensionalidad"] = st.selectbox("Reducci√≥n de dimensionalidad", ["Ninguna", "PCA", "LDA"])
        if params["Reducci√≥n de dimensionalidad"] == "PCA":
            params["Componentes"] = st.number_input("N√∫mero de componentes para PCA", min_value=1, max_value=num_features, value=2)
            params["Varianza"] = st.number_input("Varianza m√≠nima a explicar", min_value=0.0, max_value=1.0, value=0.95)
        elif params["Reducci√≥n de dimensionalidad"] == "LDA":
            params["N√∫mero de clases"] = num_classes  # Determinar autom√°ticamente
            params["Componentes"] = max_components_lda  # Ajuste autom√°tico
            st.write(f"LDA se aplicar√° con {max_components_lda} componentes (clases - 1)")
        
        
    elif selected_classifiers == "SVM":
        params["Kernel"] = st.selectbox("Tipo de kernel", ["Lineal", "Polinomial", "RBF"])
        params["C"] = st.number_input("Valor de C", min_value=0.1, value=1.0)
    elif selected_classifiers == "Random Forest":
        params["√Årboles"] = st.number_input("N√∫mero de √°rboles", min_value=1, value=100)
        params["Profundidad"] = st.number_input("Profundidad m√°xima", min_value=1, value=10)
    elif selected_classifiers == "Red Neuronal":
        params["Capas"] = st.number_input("N√∫mero de capas ocultas", min_value=1, value=3)
        params["Neuronas"] = st.number_input("Neuronas por capa", min_value=1, value=64)
    elif selected_classifiers == "KD-Tree":
        params["M√©trica"] = st.selectbox("M√©trica de distancia", ["Euclidiana", "Manhattan", "Chebyshev"])
        params["K"] = st.number_input("N√∫mero de vecinos (K)", min_value=1, value=3)
        params["T√©cnica de validaci√≥n"] = st.selectbox("T√©cnica de validaci√≥n", ["Holdout", "K-Fold"])
        if params["T√©cnica de validaci√≥n"] == "K-Fold":
            params["Folds"] = st.slider("N√∫mero de Folds", min_value=2, max_value=20, value=5)
        elif params["T√©cnica de validaci√≥n"] == "Holdout":
            params["Proporci√≥n"] = st.number_input("Proporci√≥n de datos de entrenamiento", min_value=0.1, max_value=0.9, value=0.8)
    
    # Crear columnas para los botones con espacio
    col1, col2 = st.columns([1, 1])

    with col1:
        if st.button("‚úÖ Guardar configuraci√≥n", use_container_width=True):
            st.session_state.classifier_configs.append({"Clasificador": selected_classifiers, "Par√°metros": params})
            with st.spinner("Guardando configuraci√≥n..."):
                sleep(1)
            st.success(f"Configuraci√≥n de {selected_classifiers} guardada correctamente.")
            st.rerun()

    with col2:
        if st.button("üîÑ Reiniciar selecci√≥n", use_container_width=True):
            with st.spinner("Reiniciando..."):
                sleep(1)
            reset_experiment()

# Agregar animaci√≥n visual
components.html(
    """
    <style>
    @keyframes fadeIn {
        from { opacity: 0; transform: scale(0.95); }
        to { opacity: 1; transform: scale(1); }
    }
    .stButton>button {
        animation: fadeIn 0.5s ease-in-out;
        transition: all 0.3s;
        border-radius: 8px;
    }
    .stButton>button:hover {
        transform: scale(1.05);
        background-color: #4CAF50 !important;
        color: white !important;
    }
    </style>
    """,
    height=0
)

    
# Mostrar configuraciones guardadas con mejor dise√±o
if st.session_state.classifier_configs:
    st.write("## üìå Configuraciones Guardadas")
    st.info("Puede reiniciar la selecci√≥n de clasificadores o empezar los experimentos.")
    st.warning("Revise bien las configuraciones antes de continuar.")
    # Convertir configuraciones a DataFrame con formato mejorado
    df_configs = pd.DataFrame(st.session_state.classifier_configs)
    
    # Usar expander para un dise√±o m√°s limpio
    with st.expander("üìã Ver configuraciones guardadas", expanded=True):
        st.dataframe(df_configs, use_container_width=True, height=250)
    
    # Crear columnas para centrar el bot√≥n
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("üöÄ Empezar experimentos", use_container_width=True):
            with st.spinner("Ejecutando experimentos..."):
                sleep(1.5)
            st.session_state.experiment_ready = True
            st.rerun()
    
    # Animaci√≥n visual
    components.html(
        """
        <style>
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .stButton>button {
            animation: fadeIn 0.5s ease-in-out;
            transition: all 0.3s;
            border-radius: 8px;
            font-weight: bold;
        }
        .stButton>button:hover {
            transform: scale(1.05);
            background-color: #007BFF !important;
            color: white !important;
        }
        </style>
        """,
        height=0
    )

    
        
# Ejecuci√≥n de experimentos
if "experiment_ready" in st.session_state and st.session_state.experiment_ready:
    if "df" in st.session_state:
        df = st.session_state["df"]  # Usar el DataFrame procesado

        # Asegurar que X sea num√©rico
        X = df.iloc[:, :-1].values.astype(float)

        # Verificar el tipo de la √∫ltima columna
        y_raw = df.iloc[:, -1]

        # Manejo de valores faltantes
        if y_raw.isnull().any():
            st.error("‚ö†Ô∏è La columna de etiquetas contiene valores nulos. Verifica los datos.")
        else:
            # Intentar convertir a enteros
            try:
                y = y_raw.astype(int).values
            except ValueError:
                # Si falla, convertir etiquetas categ√≥ricas a n√∫meros
                from sklearn.preprocessing import LabelEncoder
                encoder = LabelEncoder()
                y = encoder.fit_transform(y_raw)  # Convierte etiquetas categ√≥ricas a n√∫meros
                st.warning("‚ö†Ô∏è Las etiquetas de salida eran categ√≥ricas y se han convertido a n√∫meros autom√°ticamente.")

            results = []
            for config in st.session_state.classifier_configs:
                classifier = config["Clasificador"]
                params = config["Par√°metros"]

                if classifier == "KNN":
                    result = run_knn(X, y, params)
                elif classifier == "Distancia M√≠nima":
                    result = run_distancia_minima(X, y, params)
                elif classifier == "KD-Tree":
                    result = run_kdtree(X, y, params)
                results.append(result)

            # Guardar resultados en JSON
            with open("results.json", "w") as f:
                json.dump(results, f, indent=4)

            st.session_state.results = results
            st.success("‚úÖ Experimentos completados con √©xito.")

        
# Mostrar resultados de experimentaci√≥n


if st.session_state.results:
    st.write("## üìä Resultados de la Experimentaci√≥n")
    
    df_results = pd.DataFrame(st.session_state.results)
    
    # Expandir el JSON de par√°metros en columnas individuales
    df_expanded = df_results.copy()
    df_expanded = df_expanded.drop(columns=["Par√°metros"]).join(df_results["Par√°metros"].apply(pd.Series))
    
    # Redondear valores num√©ricos
    numeric_cols = ["Exactitud", "Precisi√≥n", "Sensibilidad", "Especificidad", "Tiempo de ejecuci√≥n"]
    df_expanded[numeric_cols] = df_expanded[numeric_cols].apply(lambda x: x.round(4))
    
    # Usar un expander para mantener la interfaz organizada
    with st.expander("üìã Ver Resultados Detallados", expanded=True):
        st.dataframe(df_expanded, use_container_width=True, height=300)
    
    # üìä Gr√°fica del tiempo de ejecuci√≥n por experimento
    st.write("### ‚è≥ Comparaci√≥n de Tiempo de Ejecuci√≥n")
    fig_time = px.bar(
        df_expanded, 
        x=df_expanded.index, 
        y="Tiempo de ejecuci√≥n", 
        color="Clasificador", 
        hover_data=["Exactitud", "Precisi√≥n", "Sensibilidad", "Especificidad"],
        labels={"index": "Experimento", "Tiempo de ejecuci√≥n": "Tiempo (s)"},
        title="Tiempo de Ejecuci√≥n por Experimento",
        text_auto=True,
        color_discrete_sequence=px.colors.qualitative.Pastel  # Cambio de colores
    )
    fig_time.update_traces(textfont_size=12, textangle=0, textposition="outside", cliponaxis=False)
    fig_time.update_layout(
        xaxis_title="Experimento", 
        yaxis_title="Tiempo de ejecuci√≥n (s)",
        template="plotly_dark",
        margin=dict(l=40, r=40, t=40, b=40)
    )
    st.plotly_chart(fig_time, use_container_width=True)
    
    # Mostrar el experimento con menor tiempo de ejecuci√≥n
    min_time_exp = df_expanded.loc[df_expanded["Tiempo de ejecuci√≥n"].idxmin()]
    st.info(f"‚è≥ **Menor tiempo de ejecuci√≥n:** {min_time_exp['Tiempo de ejecuci√≥n']}s con {min_time_exp['Clasificador']}. Par√°metros: {min_time_exp.to_dict()}")
    
    # üìä Gr√°fica de exactitud por experimento
    st.write("### üéØ Comparaci√≥n de Exactitud")
    fig_accuracy = px.bar(
        df_expanded, 
        x=df_expanded.index, 
        y="Exactitud", 
        color="Clasificador", 
        hover_data=["Precisi√≥n", "Sensibilidad", "Especificidad", "Tiempo de ejecuci√≥n"],
        labels={"index": "Experimento", "Exactitud": "Exactitud"},
        title="Exactitud por Experimento",
        text_auto=True,
        color_discrete_sequence=px.colors.qualitative.Bold  # Cambio de colores
    )
    fig_accuracy.update_traces(textfont_size=12, textangle=0, textposition="outside", cliponaxis=False)
    fig_accuracy.update_layout(
        xaxis_title="Experimento", 
        yaxis_title="Exactitud",
        template="plotly_dark",
        margin=dict(l=40, r=40, t=40, b=40)
    )
    st.plotly_chart(fig_accuracy, use_container_width=True)
    
    # Mostrar el experimento con mayor exactitud
    max_acc_exp = df_expanded.loc[df_expanded["Exactitud"].idxmax()]
    st.info(f"üéØ **Mayor exactitud:** {max_acc_exp['Exactitud']} con {max_acc_exp['Clasificador']}. Par√°metros: {max_acc_exp.to_dict()}")
    
    # Centrar y mejorar el dise√±o del bot√≥n
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("üîÑ Reiniciar selecci√≥n", key="reiniciar_btn", use_container_width=True):
            with st.spinner("Reiniciando..."):
                sleep(1)
            reset_experiment()
    
    # Agregar animaciones y dise√±o
    components.html(
        """
        <style>
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .stButton>button {
            animation: fadeIn 0.5s ease-in-out;
            transition: all 0.3s;
            border-radius: 8px;
            font-weight: bold;
        }
        .stButton>button:hover {
            transform: scale(1.05);
            background-color: #FF5733 !important;
            color: white !important;
        }
        </style>
        """,
        height=0
    )
